"""
AI å®¢æˆ·ç«¯
"""

import json
import re
from openai import OpenAI
from typing import Dict, Any, Optional, List, Callable
from .logger import get_logger

logger = get_logger(__name__)


class AIClient:
    """AI å®¢æˆ·ç«¯ç±»"""
    
    def __init__(self, config: Dict[str, Any], mcp_server=None):
        self.config = config
        self.provider = config.get("provider", "openai")
        self.model = config.get("model", "gpt-4")
        self.api_key = config.get("api_key", "").strip()
        self.base_url = config.get("base_url", "").strip()
        self.temperature = config.get("temperature", 0.7)
        self.max_tokens = config.get("max_tokens", 4000)
        
        # MCPæœåŠ¡å™¨
        self.mcp_server = mcp_server
        
        # æ¨¡æ‹Ÿæ¨¡å¼æ ‡å¿— - åªæœ‰åœ¨æ—¢æ²¡æœ‰APIå¯†é’¥åˆæ²¡æœ‰base_urlæ—¶æ‰å¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        self.mock_mode = not (bool(self.api_key) or bool(self.base_url))
        
        logger.info(f"AI Client initialized - API Key: {'***' if self.api_key else 'None'}, Base URL: {self.base_url or 'Default'}, Mock Mode: {self.mock_mode}, MCP: {'Yes' if mcp_server else 'No'}")
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        if not self.mock_mode:
            self._init_client()
        
        # æ³¨å†ŒMCPå·¥å…·
        self._register_mcp_tools()
    
    def _init_client(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        if self.provider == "openai":
            # ä½¿ç”¨æ–°ç‰ˆæœ¬çš„OpenAIå®¢æˆ·ç«¯
            client_kwargs = {}
            
            # å¦‚æžœæœ‰APIå¯†é’¥ï¼Œä½¿ç”¨å®ƒ
            if self.api_key:
                client_kwargs["api_key"] = self.api_key
            else:
                # å¦‚æžœæ²¡æœ‰APIå¯†é’¥ä½†æœ‰è‡ªå®šä¹‰ç«¯ç‚¹ï¼Œä½¿ç”¨ä¸€ä¸ªå ä½ç¬¦å¯†é’¥
                client_kwargs["api_key"] = "sk-placeholder"
            
            # å¦‚æžœæœ‰è‡ªå®šä¹‰base_urlï¼Œä½¿ç”¨å®ƒ
            if self.base_url:
                client_kwargs["base_url"] = self.base_url
            
            self.client = OpenAI(**client_kwargs)
            logger.info(f"OpenAI client initialized with base_url: {self.base_url or 'default'}")
        else:
            raise ValueError(f"Unsupported AI provider: {self.provider}")
    
    def _register_mcp_tools(self):
        """æ³¨å†ŒMCPå·¥å…·"""
        if not self.mcp_server:
            self.available_tools = []
            return
        
        self.available_tools = [
            {
                "type": "function",
                "function": {
                    "name": "read_file",
                    "description": "è¯»å–æ–‡ä»¶å†…å®¹",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾„"}
                        },
                        "required": ["path"]
                    }
                }
            },
            {
                "type": "function", 
                "function": {
                    "name": "write_file",
                    "description": "å†™å…¥æ–‡ä»¶å†…å®¹",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾„"},
                            "content": {"type": "string", "description": "æ–‡ä»¶å†…å®¹"}
                        },
                        "required": ["path", "content"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "list_files",
                    "description": "åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "directory": {"type": "string", "description": "ç›®å½•è·¯å¾„"}
                        },
                        "required": ["directory"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_section_structure",
                    "description": "èŽ·å–é¡¹ç›®çš„ç« èŠ‚ç»“æž„",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "generate_outline",
                    "description": "ç”Ÿæˆæ ‡ä¹¦å¤§çº²",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "requirements": {"type": "string", "description": "æ‹›æ ‡è¦æ±‚"},
                            "tender_type": {"type": "string", "description": "æ‹›æ ‡ç±»åž‹"}
                        },
                        "required": ["requirements", "tender_type"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "generate_subsection_content",
                    "description": "ç”Ÿæˆç« èŠ‚å­å†…å®¹",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "section": {"type": "string", "description": "ç« èŠ‚åç§°"},
                            "subsection": {"type": "string", "description": "å­ç« èŠ‚åç§°"},
                            "requirements": {"type": "object", "description": "è¦æ±‚ä¿¡æ¯"}
                        },
                        "required": ["section", "subsection", "requirements"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "one_click_docx_export",
                    "description": "ä¸€é”®å¯¼å‡ºWordæ–‡æ¡£",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            }
        ]
        
        logger.info(f"Registered {len(self.available_tools)} MCP tools")
    
    def _call_mcp_tool(self, tool_name: str, arguments: Dict[str, Any]) -> str:
        """è°ƒç”¨MCPå·¥å…·"""
        if not self.mcp_server:
            return "MCPæœåŠ¡å™¨æœªåˆå§‹åŒ–"
        
        try:
            if tool_name == "read_file":
                result = self.mcp_server.read_file(arguments["path"])
            elif tool_name == "write_file":
                result = self.mcp_server.write_file(arguments["path"], arguments["content"])
            elif tool_name == "list_files":
                result = self.mcp_server.list_files(arguments["directory"])
            elif tool_name == "get_section_structure":
                result = self.mcp_server.get_section_structure()
            elif tool_name == "generate_outline":
                result = self.mcp_server.generate_outline(arguments["requirements"], arguments["tender_type"])
            elif tool_name == "generate_subsection_content":
                result = self.mcp_server.generate_subsection_content(
                    arguments["section"], arguments["subsection"], arguments["requirements"]
                )
            elif tool_name == "one_click_docx_export":
                result = self.mcp_server.one_click_docx_export()
            else:
                return f"æœªçŸ¥çš„å·¥å…·: {tool_name}"
            
            return json.dumps(result, ensure_ascii=False, indent=2) if isinstance(result, (dict, list)) else str(result)
            
        except Exception as e:
            logger.error(f"MCP tool call failed: {tool_name} - {e}")
            return f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
    
    def chat(self, prompt: str, system_prompt: Optional[str] = None) -> str:
        """å‘é€èŠå¤©è¯·æ±‚"""
        # å¦‚æžœæ˜¯æ¨¡æ‹Ÿæ¨¡å¼ï¼Œè¿”å›žæ¨¡æ‹Ÿå“åº”
        if self.mock_mode:
            return self._get_mock_response(prompt, system_prompt)
        
        try:
            messages = []
            
            if system_prompt:
                # å¦‚æžœæœ‰MCPå·¥å…·ï¼Œåœ¨ç³»ç»Ÿæç¤ºä¸­è¯´æ˜Žå¯ç”¨å·¥å…·
                if self.available_tools:
                    tool_descriptions = []
                    for tool in self.available_tools:
                        func = tool["function"]
                        tool_descriptions.append(f"- {func['name']}: {func['description']}")
                    
                    enhanced_system_prompt = f"""{system_prompt}

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ï¼š
{chr(10).join(tool_descriptions)}

å½“éœ€è¦ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·åœ¨å›žå¤ä¸­åŒ…å«ç±»ä¼¼è¿™æ ·çš„æ ¼å¼ï¼š
TOOL_CALL: tool_name(å‚æ•°)

ä¾‹å¦‚ï¼š
- TOOL_CALL: get_section_structure()
- TOOL_CALL: read_file(path="/path/to/file")
- TOOL_CALL: generate_outline(requirements="éœ€æ±‚", tender_type="ç±»åž‹")"""
                    messages.append({"role": "system", "content": enhanced_system_prompt})
                else:
                    messages.append({"role": "system", "content": system_prompt})
            
            messages.append({"role": "user", "content": prompt})
            
            if self.provider == "openai":
                logger.info(f"Sending request to model: {self.model}")
                
                # æž„å»ºè¯·æ±‚å‚æ•°
                request_params = {
                    "model": self.model,
                    "messages": messages,
                    "temperature": self.temperature,
                    "max_tokens": self.max_tokens,
                    "stream": False
                }
                
                # å°è¯•ä½¿ç”¨function calling
                if self.available_tools:
                    try:
                        request_params["tools"] = self.available_tools
                        request_params["tool_choice"] = "auto"
                        
                        response = self.client.chat.completions.create(**request_params)
                        message = response.choices[0].message
                        
                        # å¦‚æžœAIæƒ³è¦è°ƒç”¨å·¥å…·
                        if hasattr(message, 'tool_calls') and message.tool_calls:
                            tool_results = []
                            
                            for tool_call in message.tool_calls:
                                tool_name = tool_call.function.name
                                try:
                                    arguments = json.loads(tool_call.function.arguments)
                                except json.JSONDecodeError:
                                    arguments = {}
                                
                                logger.info(f"AI calling tool: {tool_name} with args: {arguments}")
                                
                                # è°ƒç”¨MCPå·¥å…·
                                tool_result = self._call_mcp_tool(tool_name, arguments)
                                tool_results.append(f"å·¥å…· {tool_name} æ‰§è¡Œç»“æžœ:\n{tool_result}")
                            
                            # å°†å·¥å…·ç»“æžœæ·»åŠ åˆ°å¯¹è¯ä¸­ï¼Œè®©AIç”Ÿæˆæœ€ç»ˆå›žå¤
                            messages.append({
                                "role": "assistant", 
                                "content": message.content or "æˆ‘å°†ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©æ‚¨ã€‚"
                            })
                            
                            for i, tool_call in enumerate(message.tool_calls):
                                messages.append({
                                    "role": "tool",
                                    "tool_call_id": tool_call.id,
                                    "content": tool_results[i]
                                })
                            
                            # å†æ¬¡è¯·æ±‚AIç”Ÿæˆæœ€ç»ˆå›žå¤
                            final_response = self.client.chat.completions.create(
                                model=self.model,
                                messages=messages,
                                temperature=self.temperature,
                                max_tokens=self.max_tokens
                            )
                            
                            result = final_response.choices[0].message.content.strip()
                            logger.info(f"Received response from AI model (length: {len(result)})")
                            return result
                        else:
                            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨æŒ‡ä»¤
                            result = message.content.strip()
                            return self._process_text_tool_calls(result)
                    
                    except Exception as e:
                        logger.warning(f"Function calling failed, falling back to text parsing: {e}")
                        # é™çº§åˆ°æ™®é€šèŠå¤©
                        request_params.pop("tools", None)
                        request_params.pop("tool_choice", None)
                
                # æ™®é€šèŠå¤©è¯·æ±‚
                response = self.client.chat.completions.create(**request_params)
                result = response.choices[0].message.content.strip()
                
                # æ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨æŒ‡ä»¤
                result = self._process_text_tool_calls(result)
                
                logger.info(f"Received response from AI model (length: {len(result)})")
                return result
            
        except Exception as e:
            logger.error(f"AI chat request failed: {e}")
            if "api_key" in str(e).lower() or "authentication" in str(e).lower():
                return "âš ï¸ APIå¯†é’¥è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"
            elif "connection" in str(e).lower() or "network" in str(e).lower():
                return f"âš ï¸ ç½‘ç»œè¿žæŽ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç«¯ç‚¹ {self.base_url} æ˜¯å¦å¯è®¿é—®ã€‚"
            else:
                return f"âš ï¸ AIæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}"
    
    def _process_text_tool_calls(self, text: str) -> str:
        """å¤„ç†æ–‡æœ¬ä¸­çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤"""
        if not self.available_tools or "TOOL_CALL:" not in text:
            return text
        
        # æŸ¥æ‰¾å·¥å…·è°ƒç”¨æŒ‡ä»¤
        import re
        tool_call_pattern = r'TOOL_CALL:\s*(\w+)\((.*?)\)'
        matches = re.findall(tool_call_pattern, text)
        
        if not matches:
            return text
        
        result_parts = [text]
        
        for tool_name, args_str in matches:
            logger.info(f"Text-based tool call detected: {tool_name}({args_str})")
            
            # è§£æžå‚æ•°
            arguments = {}
            if args_str.strip():
                try:
                    # ç®€å•çš„å‚æ•°è§£æž
                    for arg in args_str.split(','):
                        if '=' in arg:
                            key, value = arg.split('=', 1)
                            key = key.strip().strip('"\'')
                            value = value.strip().strip('"\'')
                            arguments[key] = value
                except Exception as e:
                    logger.warning(f"Failed to parse arguments: {args_str}, error: {e}")
            
            # è°ƒç”¨å·¥å…·
            tool_result = self._call_mcp_tool(tool_name, arguments)
            
            # æ·»åŠ å·¥å…·ç»“æžœåˆ°å›žå¤ä¸­
            result_parts.append(f"\n\n**{tool_name} æ‰§è¡Œç»“æžœï¼š**\n{tool_result}")
        
        return "\n".join(result_parts)
    
    def _get_mock_response(self, prompt: str, system_prompt: Optional[str] = None) -> str:
        """èŽ·å–æ¨¡æ‹Ÿå“åº”"""
        prompt_lower = prompt.lower()
        
        # æ„å›¾åˆ†æžçš„æ¨¡æ‹Ÿå“åº”
        if "åˆ†æžç”¨æˆ·çš„æ„å›¾" in prompt or "analyze" in prompt_lower:
            if "åˆ›å»ºé¡¹ç›®" in prompt or "create" in prompt_lower:
                return '''
{
    "intent": "create_project",
    "confidence": 0.9,
    "entities": {
        "project_name": "æ™ºæ…§åŸŽå¸‚å»ºè®¾é¡¹ç›®"
    },
    "task_type": "simple",
    "requires_planning": false
}
'''
            elif "ç”Ÿæˆå¤§çº²" in prompt or "outline" in prompt_lower:
                return '''
{
    "intent": "generate_outline",
    "confidence": 0.9,
    "entities": {},
    "task_type": "simple",
    "requires_planning": false
}
'''
            elif "æŸ¥çœ‹" in prompt or "view" in prompt_lower:
                return '''
{
    "intent": "view_content",
    "confidence": 0.8,
    "entities": {},
    "task_type": "simple",
    "requires_planning": false
}
'''
            elif "å¯¼å‡º" in prompt or "export" in prompt_lower:
                return '''
{
    "intent": "export_document",
    "confidence": 0.9,
    "entities": {},
    "task_type": "simple",
    "requires_planning": false
}
'''
        
        # ä¸€èˆ¬å¯¹è¯çš„æ¨¡æ‹Ÿå“åº”
        return """
ðŸ¤– **æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œä¸­**

ç”±äºŽæœªé…ç½® API å¯†é’¥ï¼Œå½“å‰è¿è¡Œåœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹ã€‚

ðŸ’¡ **é…ç½® API å¯†é’¥**ï¼š
1. è¿è¡Œ `tender` å‘½ä»¤
2. æŒ‰æç¤ºè¾“å…¥ OpenAI API Key
3. å®Œæˆé…ç½®åŽå³å¯ä½¿ç”¨å®Œæ•´åŠŸèƒ½

ðŸ“ **å½“å‰åŠŸèƒ½**ï¼š
- âœ… é¡¹ç›®ç®¡ç†ï¼ˆåˆ›å»ºã€åˆ—è¡¨ã€åˆ‡æ¢ï¼‰
- âœ… æ–‡ä»¶æ“ä½œï¼ˆè¯»å†™ã€ç›®å½•ç®¡ç†ï¼‰
- âœ… å¤§çº²ç”Ÿæˆï¼ˆä½¿ç”¨å†…ç½®æ¨¡æ¿ï¼‰
- âœ… Wordæ–‡æ¡£å¯¼å‡º
- âš ï¸ AIå†…å®¹ç”Ÿæˆï¼ˆéœ€è¦APIå¯†é’¥ï¼‰

ðŸš€ **å¼€å§‹ä½¿ç”¨**ï¼šå³ä½¿åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½“éªŒå¤§éƒ¨åˆ†åŠŸèƒ½ï¼
"""
    
    def generate_content(self, prompt: str, context: Optional[Dict[str, Any]] = None) -> str:
        """ç”Ÿæˆå†…å®¹"""
        full_prompt = prompt
        
        if context:
            context_str = "\n".join([f"{k}: {v}" for k, v in context.items()])
            full_prompt = f"{context_str}\n\n{prompt}"
        
        return self.chat(full_prompt)
    
    def analyze_text(self, text: str, analysis_type: str = "general") -> Dict[str, Any]:
        """åˆ†æžæ–‡æœ¬"""
        prompt = f"""
è¯·åˆ†æžä»¥ä¸‹æ–‡æœ¬å¹¶è¿”å›žJSONæ ¼å¼çš„ç»“æžœï¼š

åˆ†æžç±»åž‹ï¼š{analysis_type}
æ–‡æœ¬å†…å®¹ï¼š{text}

è¯·æå–å…³é”®ä¿¡æ¯å¹¶ç»“æž„åŒ–è¿”å›žã€‚
"""
        
        response = self.chat(prompt)
        
        try:
            import json
            return json.loads(response)
        except:
            return {"raw_response": response}
    
    def is_available(self) -> bool:
        """æ£€æŸ¥AIæœåŠ¡æ˜¯å¦å¯ç”¨"""
        if self.mock_mode:
            return True  # æ¨¡æ‹Ÿæ¨¡å¼æ€»æ˜¯å¯ç”¨
        
        try:
            # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
            test_response = self.chat("Hello", "You are a helpful assistant. Please respond with 'OK'.")
            is_ok = bool(test_response) and "âš ï¸" not in test_response and len(test_response.strip()) > 0
            logger.info(f"AI availability test: {'PASS' if is_ok else 'FAIL'} - Response: {test_response[:50]}...")
            return is_ok
        except Exception as e:
            logger.error(f"AI availability test failed: {e}")
            return False 